--author Clarissa The Adjoint
--title What can we teach the cyborg student?
--date today

--newpage
--heading What are we going to talk about?
 * The current state of LLM and LLM-agents
 * Where the technology is likely to go in the next few years
 * How do we use tools when learning?
 * How do tools affect cognitive processes?
 * Applications of extended mind
 * Epistemic practices in a world of knowledge-work automation
--newpage
--heading Whither ethics and environment
--center Let's get something big out of the way first
---
* This talk is on the science and engineering of LLMs and how they can/should impact higher-education
* We're dealing with necessities not contingencies
* The environmental impacts of hyperscale datacenters are almost entirely knock-on effects of the power infrastructure surrounding them
  * Clean and renewable would make them cost almost nothing
  * Dirty and inefficient, like xAI's methane burning generators, have a massive impact
* The regulation and policy around how/if private labs are allowed to use public infrastructure to build these artifacts is *beyond the scope of this talk*
* Related: Open source artifacts capable of running on a home computer are only a year behind the frontier models


--newpage
--heading What can LLMs actually do?

--center I apologize but this is going to be a bit long, there's a lot of catching up to do
--newpage
--heading What can LLMs actually do?
--center  First we're going to have to undo some misconceptions and misinformation
---
  * LLMs can spell strawberry and garlic
---
  * LLMs can do math
---
  * LLMs can write large quantities of high-quality code
---
  * LLMs can double-check their own sources
---
  * LLMs can fix their own mistakes before presenting their final result
--newpage
--heading Wait, what?
 Yes, LLMs *were* bad at many things for the first year, year and a half after the original ChatGPT (GPT 3.5). Essentially they were toys and a lot of people were overhyping their abilities.
---
Anyone else remember the flood of "courses" that were going to teach *you* how to turn Chat GEE PEE TEE into a source of Passive Income!
---
 But the underlying technology has been changing.
---
 Quickly.

--newpage
--heading What changed?
 There are two major things that changed:
 * Reasoning
 * Tool use
--newpage
--heading Reasoning?!
Caveat: there are ways we have to talk about these things that are going to sound anthropomorphizing. There's not really a good way around that. Sorry
--newpage
--heading Reasoning

 In LLM research "reasoning" is the ability to generate an "internal monologue" that the LLM reflects on before finalizing its response.

 Having this "scratch pad" of thought massively improves LLM's reliability in mathematics, programming, and logical reasoning.

 It's still, by itself, a limited trick: it takes LLMs from toys to being capable of *some* small knowledge-work tasks

--heading In summary
 Important Lesson #1: Not all models are equal
---
 Important Lesson #2: The underlying technology is changing rapidly
---
 Important Lesson #3: You must constantly re-evaluate limitations
---
 Petty Lesson #1: Don't trust anyone's word if they don't specify the model they're talking about

--newpage The extended mind
--newpage We think with tools
--newpage LLMs and their strengths